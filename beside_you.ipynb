{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a1a0c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found .env file at: d:\\Ai agents\\iambesideyou\\.env\n",
      "\n",
      "üîë --- Checking Keys Found ---\n",
      "  - Key: LANGSMITH_TRACING, Length: 4\n",
      "  - Key: LANGSMITH_API_KEY, Length: 51\n",
      "  - Key: GOOGLE_API_KEY, Length: 39\n",
      "  - Key: TAVILY_API_KEY, Length: 41\n",
      "  - Key: LANGSMITH_PROJECT, Length: 17\n",
      "  - Key: OPENAI_API_KEY, Length: 164\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "from dotenv import dotenv_values, find_dotenv\n",
    "import os\n",
    "\n",
    "\n",
    "dotenv_path = find_dotenv()\n",
    "\n",
    "\n",
    "if not dotenv_path:\n",
    "    print(\"‚ùå Error: Could not find the .env file in this directory or any parent directories.\")\n",
    "else:\n",
    "    print(f\"‚úÖ Found .env file at: {dotenv_path}\\n\")\n",
    "    \n",
    "    \n",
    "    config = dotenv_values(dotenv_path)\n",
    "\n",
    "    if not config:\n",
    "        print(f\"‚ö†Ô∏è The .env file is empty or could not be parsed.\")\n",
    "    else:\n",
    "        print(f\"üîë --- Checking Keys Found ---\")\n",
    "        for key, value in config.items():\n",
    "            if value:\n",
    "                \n",
    "                print(f\"  - Key: {key}, Length: {len(value)}\")\n",
    "            else:\n",
    "                print(f\"  - Key: {key}, Value: (empty)\")\n",
    "        print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a216c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, BaseMessage,AnyMessage,ToolMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "\n",
    "class MessagesState(MessagesState):\n",
    "    # Add any keys needed beyond messages, which is pre-built \n",
    "    pass\n",
    "\n",
    "builder= StateGraph(MessagesState)\n",
    "\n",
    "builder.add_node()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "803ab579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Google API Key loaded and validated successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import sys \n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "\n",
    "if not api_key:\n",
    "    print(\"üö® Error: GOOGLE_API_KEY not found in .env file.\")\n",
    "    sys.exit(1) \n",
    "\n",
    "if len(api_key) < 30: \n",
    "    print(\"üö® Error: The provided GOOGLE_API_KEY seems too short to be valid.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "print(\"‚úÖ Google API Key loaded and validated successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44f5453f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph compiled! You can now interact with it.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "from typing import TypedDict, Annotated, List\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage, BaseMessage, ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "@tool\n",
    "def add_subject(subject: str) -> str:\n",
    "    \"\"\"Adds a subject to the list of subjects.\"\"\"\n",
    "    return f\"Successfully added '{subject}'. The user should be notified of this success.\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def delete_subject(subject: str) -> str:\n",
    "    \"\"\"Deletes a subject from the list of subjects.\"\"\"\n",
    "    return f\"Successfully deleted '{subject}'. The user should be notified of this success.\"\n",
    "\n",
    "tools = [add_subject, delete_subject]\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], lambda x, y: x + y]\n",
    "    subjects: List[str]\n",
    "\n",
    "\n",
    "\n",
    "def call_model(state: GraphState):\n",
    "    print(\"---AGENT---\")\n",
    "    messages = state['messages']\n",
    "    model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0)\n",
    "    model_with_tools = model.bind_tools(tools)\n",
    "    response = model_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "\n",
    "\n",
    "def update_state_from_tool_calls(state: GraphState) -> GraphState:\n",
    "    print(\"---UPDATING SUBJECTS LIST---\")\n",
    "    last_message = state['messages'][-1]\n",
    "    \n",
    "    if not hasattr(last_message, 'tool_calls') or not last_message.tool_calls:\n",
    "        return state\n",
    "\n",
    "    current_subjects = state.get('subjects', [])\n",
    "    \n",
    "    for tool_call in last_message.tool_calls:\n",
    "        tool_name = tool_call.get('name')\n",
    "        tool_args = tool_call.get('args', {})\n",
    "        subject = tool_args.get('subject')\n",
    "        \n",
    "        if not subject:\n",
    "            continue\n",
    "\n",
    "        if tool_name == 'add_subject':\n",
    "            if subject not in current_subjects:\n",
    "                print(f\"Adding '{subject}' to the list.\")\n",
    "                current_subjects.append(subject)\n",
    "        elif tool_name == 'delete_subject':\n",
    "            if subject in current_subjects:\n",
    "                print(f\"Deleting '{subject}' from the list.\")\n",
    "                current_subjects.remove(subject)\n",
    "\n",
    "    \n",
    "    return {\"subjects\": current_subjects}\n",
    "\n",
    "\n",
    "\n",
    "def should_continue(state: GraphState):\n",
    "    last_message = state['messages'][-1]\n",
    "    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "        return \"continue_to_tools\"\n",
    "    else:\n",
    "        return \"end_conversation\"\n",
    "\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Add the nodes\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"update_state\", update_state_from_tool_calls)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Set the entry point\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "# Add the conditional edge\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"continue_to_tools\": \"update_state\", \n",
    "        \"end_conversation\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "workflow.add_edge(\"update_state\", \"tools\")\n",
    "workflow.add_edge(\"tools\", \"agent\") \n",
    "\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "print(\"Graph compiled! You can now interact with it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86c3f11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---AGENT---\n",
      "---UPDATING SUBJECTS LIST---\n",
      "Adding 'Physics' to the list.\n",
      "---AGENT---\n",
      "\n",
      "---FINAL RESPONSE---\n",
      "OK. I've added Physics to your subjects. Anything else?\n",
      "\n",
      "---UPDATED SUBJECTS---\n",
      "['Chemistry', 'Biology', 'Physics']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "initial_state = {\n",
    "    \"messages\": [HumanMessage(content=\"Hi! Can you please add 'Physics' to my subjects?\")],\n",
    "    \"subjects\": [\"Chemistry\", \"Biology\"] \n",
    "}\n",
    "\n",
    "final_state = app.invoke(initial_state)\n",
    "\n",
    "\n",
    "print(\"\\n---FINAL RESPONSE---\")\n",
    "print(final_state['messages'][-1].content)\n",
    "print(\"\\n---UPDATED SUBJECTS---\")\n",
    "print(final_state['subjects'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f337b3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---AGENT---\n",
      "---UPDATING SUBJECTS LIST---\n",
      "Deleting 'Chemistry' from the list.\n",
      "---AGENT---\n",
      "\n",
      "---FINAL RESPONSE---\n",
      "OK. I've removed 'Chemistry'. Anything else?\n",
      "\n",
      "---UPDATED SUBJECTS---\n",
      "['Biology', 'Physics']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "initial_state_delete = {\n",
    "    \"messages\": [HumanMessage(content=\"You know what, please remove 'Chemistry'\")],\n",
    "    \"subjects\": [\"Chemistry\", \"Biology\", \"Physics\"] \n",
    "}\n",
    "\n",
    "final_state_delete = app.invoke(initial_state_delete)\n",
    "\n",
    "\n",
    "print(\"\\n---FINAL RESPONSE---\")\n",
    "print(final_state_delete['messages'][-1].content)\n",
    "print(\"\\n---UPDATED SUBJECTS---\")\n",
    "print(final_state_delete['subjects'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb4722fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUYAAAF0CAIAAADQBwcBAAAQAElEQVR4nOydB3wURRvGZ+8uvZEESAKBhBCQKqEXkY5IrwLSm3QVAQsgH70joCJNUARERUCQ3gQV6UiQEmooAVIIIb3c5W6/527DcZByl3CX3O69/x+/YzNbbndunnnfeWd2RsHzPCMIQiooGEEQEoIkTRCSgiRNEJKCJE0QkoIkTRCSgiRNEJKCJE2Ymatnku9dSUmOV2Wka9TKbF2kHGMvpcl5puY4OePVWQkyBdNkZjtPf4DBFTgZz2u4l49U8HymNpHjmGEXLadgfLbL6q7Hyx04OweFV0m7ctVdy7/uzMQMR/3ShFk49uvj8CvJ6clqTsbZO8js7OVyO16tMl66BAFzco5XZx0sV3DqzJdPlCuYWhCkoaQVHJ/tSJmdTKPS6LY4puENvojTZOZwP7hhTsZUGXymis9Uak9w9VBUa+BRq1UxJkJI0sSrcnBTTPilZEiudLDzGx1KeJSQMzHz4HrGmUOxMRHpkHqdFsVrt3ZnooIkTbwSaz+/A7PZqEOJKvVdmbQ4vuPJ1dMJji6KAZ+XZeKBJE0UkMsnEv7cHlu5rnuLXiWYdPntm4eRd9JHLy7PRAJJmigIKQnqH2beHb2wPBO3l20SNy+kHtj4aNSiYLkYHpYkTeSbi8cSTu6LHblANIbLLHwz4fYYMVRhMkYQ+SEljv2z2+b0DNoNKrVy0m1m9ZCkifyxcUF47ZZezPYoV93Jr5zz+pn3mHVDkibywfbljxyc5fXbejKbpMsov/SUzLP7nzIrhiRN5IPIO6ndRpZmNkyNJp7//kmSJiTBjm8iHZ0VHj42PYi4YXsvjZo/d8h6VU2SJkzl0d3Uao0KdYzk7du3O3TowPLPli1bpk2bxiyDb4DTpRMJzFohSRMmEXk3k9ew+m0LVdJXr15lBaLAJ5pCw3bFUxMzmbVCb2IRJhF6NM7RyVIGICkpadWqVcePH4+Li6tSpUrbtm27dOmClLVr12JvnTp1Pvroo759+/79998HDhy4cOFCQkJCtWrVhg0bhl044NatW7179162bNns2bM9PT3d3Nz+/fdfpO/Zs2fTpk2VKlViZsW3nL1MzoWdSalcz4VZHyRpwiSeRKe7FrNjlmHGjBnR0dGTJk0qV64cfOZ58+YFBQWNHDlSqVQePHhw9+7dOCY9Pf3zzz+vV68eDsafhw8fhs537Njh7e1tZ6e9Mei/f//+ISEhVatWHTRoUEBAgHCkJXBwkt+/TpImxIwqTeNVzp5ZBhjVAQMGNGjQANvvv/9+q1atihV72cN3dHT8+eefnZychF2w0lu3bg0NDW3ZsiXHad+Oxumw5KxQcHCUJz1RMauEJE2YhFrNOztZajAkTCs85Pj4+Fq1ajVs2LBy5co5HpaSkrJ8+fLz58/HxsYKKU+fPo8853aWJZDZw2uw0uY0hccIk1BrNLycY5Zh+vTpffr0OXny5Pjx41u3br1y5crMzJcFExUVhcazSqWaO3cujjx16tRLBzg4OLDCQg7HgLdUbrwiZKUJk1DIZenJamYZ3N3dhwwZMnjw4IsXLx49enTdunUIcfXr18/wmEOHDqFpjeYxfG/2on0ufNQq3sHJSl/gIEkTJmHvKE9+apHWI8LX+/fv79y5M1rLITquX79+7dq17IdB+YKewZEjR1jRkZqk9vW2Uu2Q402YhJuXIj5WySyAQqFYs2bNp59+ChP95MkT9DxBzxA2dpUtWxbN5mPHjt27d69ChQrY3rZtG3zyEydOnDlzBnEyeOM5XrNMmTKXL18+e/YsesWYBVAp1aWDrXQWF5I0YRKvN/RQpmuYBXBxcVm0aFFMTMzQoUPbtGmzYcOGcePGdevWDbsaN24MbU+cOBHd0diFA7799ltEtjdv3vzJJ5+0a9du/fr1aFpnvyZOR2t3zJgxN2/eZOYmIVadqeJDmrkxq4SmQCBMZfn4W816lKjWyIPZNru/jXwUnjZ8XhCzSshKE6bi5Wtvza8rFBoPbqVWqGWlJppReIwwnZ7jy678OC8/Fo1edEfluMvDwwPxrRx3denSBZ42swy4cmhoaI67MjIycuv3Wrt2bXBwcI67Lp9IgNfd/B3rnUGRHG8iH/w4/z4KTL9JATnuTUtLy61vCbv0weqXcHZ2zj5WzFwgooaurxx3JSYmIoSe466SJUsiaJfjrtWTbper4vZW/5LMWiFJE/ljxcRb7YeUCahSeOM6rIc/fnl8+7/k9+aUY1YMtaWJ/NGsh8/e9Q+YDaJmYacTrFzPjCRN5JcqDdwCK7t+N+0uszFWTQpv0cuXWT3keBMF4ea5lCNbo0fOt9KOHLOzfMKtnh+WLVnWUu+imRGSNFFA9v8Qc+dKUtv+pQKrOzHpcmJX3L9H497q51uxljgW/SJJEwUn7HTysW0xHsXt+nxShkmOmHuqPd89VCr5wf8rZy+eWoskTbwqPy+OeBKZ4e5lX7OJZ7U3rXcMhunAMl8/n5iWrPYPdu400o+JCpI0YR62ffXo8aMMXqOxd5K7uMpd3O0UDixT9cKwcE7GeA2TyZhG98mj+D1b0t3wT5mMw39Z2wptIq954RgcoNHu1S4ez2kjvFmJPON5gyvLFTINjhO+UXtF7Q0Ibznz2kOzFpHHYdhWpmhSktWpiZmqDLXCXuZfwbn9UBEEw7JDkibMycNbyssnn8ZFKTNS1ZmZvCrjhdLFaYubdlohFDrd5EIQq+zZLqY9VHe4VqW89khsy+SMV2sPF47BDrWaV2i1+vxqwnW09QXkq9sQTteeq3l2DK+7NqfhdL08Gu3VtQdo1EyGJAVT2MmcXe28/e0atPZ29RbxepwkaUJMREdHDxkyZM+ePYzIBRrjTYiJzMzM3IZqEgKUO4SYIEkbhXKHEBMkaaNQ7hBiApIWJuIncoMkTYgJstJGodwhxARJ2iiUO4SYgKTlchF3GhcCJGlCTKhUKmpL5w1JmhAT5HgbhXKHEBMkaaNQ7hBigiRtFModQkyQpI1CuUOICQqPGYUkTYgJstJGodwhxARJ2iiUO4SYIEkbhXKHEBPUljYKSZoQE2SljUK5Q4gJkrRRaAEdQkyo1WqSdN6QpAkxQVbaKJQ7hJhAeIwknTeUO4SYICttFModQkw46mBE7pCkCTGhVCpTU1MZkTskaUJMwOuG782I3CFJE2KCJG0UkjQhJkjSRiFJE2KCJG0UGmpCiAmStFHIShNigiRtFJI0ISZI0kYhSRNigiRtFJI0ISZI0kYhSRNigiRtFJI0ISZI0kYhSRNigiRtFJI0ISZI0kYhSRNigiRtFJI0ISZI0kYhSRNigiRtFI7neUYQ1s3AgQMvXbrEcdriKnwiUaPRhIaGMuJF6LUNQgSMHj26RIkSELNMJhM+oeo6deowIhskaUIE1K9fv0qVKoYpbm5uAwYMYEQ2SNKEOBg2bJinp6f+z6CgoCZNmjAiGyRpQhxUrVq1Vq1awra9vX3fvn0ZkRMkaUI0wFCXLFkSG4GBga1bt2ZETlDEmzAzty+mhV9JTk9Raf+AydDo/pdxGo22pMkUnCaTfyFFhti19hi5glNnPiuNHGM8e76X4xhi3TIWdu1aTHRMhQoV/Xx9tUfJOF577vMyzGmNFBJ1V+aYRr9HprsXzfP7fOHrcI6cc3KyD3nDzbusPRMzJGnCbKiVbP3se6qMTDsHuTJNqx6dErW7oDSd9qAcnldzhinPZS/nNbpduuOe6VS3kXUd3U70XSHi/Wwvz3juhZvgngtc/+26r9P2fxloX6thXv2CpO3sOFWGxtldPuDzACZaSNKEeYCe13weXjHEs157TyZmDm6MSnicPmRGIBMnJGnCPKz+7E6Dtj5BIc5M/Oz/ISrlacagaaK01RQeI8zAkU2P7Rxk0tAzeHugb0aa+uZ5Ua7UQ5ImzEBkRJq7tx2TEA6O8uv/JjARQpImzEBGqkZi7Te1Rp2WIsr3Q+hNLMIMZEIBKg2TEBoNp1aLspoiSRNETvCGndpighxvgsgRXjtURYSQlSbMACfjOVGW/7whSRO2Cq/hJDe+gXth+Kh4IMebIHKCI8ebsGG0hV9i1oHCY4RNIxOpScsDtCTIShO2ikat/SclOBknF6e9I0kTRE7wTKTxPpI0QeQAFC3SlxRJ0oQZ0HZKS6wt/eJ8CSKCJE2YAZlMO/EQI6wAingTZkCtDY9Zr1Hr2r31o8iHzDYgK01InKioyPj4p8xmICtNFA137tz+8qsFAwf3aNO20YiR/Xb+vlW/6+rVS8NH9G3X4c1PJ31w5cp/7384dOmyecKuuLgns+dM6d2nQ5durebMmxoRcU9I/23Hlm493rp//+7goT2bt6wz9L3e+w/sQvqF0HPv9u2Ijb79Oi9cNNPku0N0gEaPETYMl//RY9+s+CIq6tH48VM4joMUIW8fH78G9d9IT0+f/PlHr1WsPHPG4sSkhGVfzo+Liy0fVIFp3Xv1RxNGpKQkfzzxfxWCX/v5lw2jxwxctWpT6VL+dnZ2yclJX3298OMJUytXrrZx0zoIuGZI3ZohdebNWTZpyrgfN+0s5Vfa9NvjafQYYevks/xPnTpv0aIVtWpqVde5Uw9o+MzZE0g/dfp4QkL8iOEf+vr6VaxQ6b1hY6Ojo4RTLl0KhfgnT5pVv14jLy/vUSPHuXsU27Zts7BXpVINHDC8SpXqqCPavNUBXVC3bl1nBYVnGpHG8MlKE0UEz2/f/vPpM//onWc/nRW9c+eWq6trUFCwkAjBu7m5C9uXLofCGqMWEP6EdENq1L7437/6S1aqVFXYEE6B3WYFRcZpl8hkIoQkTZgB7aCM/FhpjUbz2eQPVSoljHAIROvqhgazsCspOcnZ2cXw4GLFsiYGh0RhitFUznEv04mcmQmeRo8RhOncuHnt2rUrixetqF2rnpACuZYorl3vytHBUalUGh785MljYcPbu7iTk9Oc2UsN98plcmYBEB4T6aQOJGnCDOS39KO1jE9Bw+Du3XD8KxdYHtulS5dBnxMi22gtM13IOjU1az7t8uUrpqWllSzpi3iYkILe5mIeFlncA+ExXpzTCVJ4jDADHOO5/BSlwIAghULxy5aNiUmJiHh9vXxR3ToNoqIjsatB/cZyuRwpKSkpDx5GbNy4tkSJLOXDpNer12jx4lkImKFS2LHz15Gj+u/f/3ve31WmbCA+jx07dPMVomUigiRNmAENz/H5mdXHx8d3yuTZV8Mude7SAl1Ww4aO6dSpR1jYZXRTw7v+aNwkBL26v/PWgoXT+/QZ7OTkrFBkzfuPHqmmTVvNnD0J/dLbf/u5Vau23br1zvu7YNLfbtPx+/WrNm/+npmMePulaU0swgysnhzu4W3ffpg/MwcPHz1AyNpdF7VG+ezQqemQQaO6d3+XFSI/L7zrVozr/bH4lsWitjRhXcCjHj1mYHD5ikOHjvH09Fq37hv0JzVrRgvEmwo53oR14eFRbP7cL2Gc/zdt4ogRfZOSEr9Z4M1rSgAAEABJREFUvh7eOCtsaEAoYcMoFJzcfEWpcuVqS75YxYoYsQ4IJUkTZiAzk1eLck24vODIShOEZND2ydFQE4KQDmKdeowkTZgDjmOctCKt4n25kiRNmAGOSW9NLLFCnVjEq3Lu3Lmk5GSxvrgkOUjSRAH5/fffV6xYgQ0nJydXV2fJFSWx9kuTpIn8cePGDXyGhYVdvHixffv22K5ataqu5cmkBbWlCUmD+C/HcaNGjdJoNKtXr65cufLUqVMZYX2QpAkj3Lt3b926db169YI1njBhQnBwMCOsGHK8iZxJTEz877//sHHkyJEGDRpAz9jOTc/2jjJ7B0mVJQdnztHZjokQkjSRAwhid+nSRZhOZMiQIe3atcv7eDc3RVqKpELeqnTeo7g9EyEkaSILNJLXrFkzceJEbPv7+//xxx8wziaeW6uFd3JcOpMKykSmTNc071X4r3+ZAZI0wY4ePZqRkZGQkMC002trg16+vr75ukJQDSePEo5bF99nkmDbijsVQtyZOKFZTWwX+NXOzs7Dhw/38PCYP3++XP6qU23+8Uts+KXkUkHO/uVd1ezlN7O0I8zQ2audmNeg0HFZswU/2/vin0w31hRHa//i9InCUbzu7+fHsGcvWvDshatzuiT+hU5mTibjNS92u8nlvFJzNyw1JiKldR/fTb8tCggI8PPz89Xh4+PDRAJJ2ha5fv36kiVLBg0a1LBhw5SUFBcXF2YmTu6Ou3Y+UZmmUWVk66fm8pzrO2tvLgcJyS/t1P9pmJ7TBfjsb1VlP4xjiPA5utjVa+N998lfs2bNyszMLFasGGo9hULbMYTGSGBg4IcffsisG5K0DXHjxg30SLVu3frgwYPe3t61a9dmYuPx48cDBgzYt28fszAjRow4e/asTJbVMuWfceHCBWbdUFta+gi19pUrV6ZPn+7l5YXtt956S4x6Zrr1NMqUKcMsz6hRo4S80n8vPq1fz4ystOSZO3fumTNnduzYYV4H2xYYP378n3/+qV+Ux9PT89ChQ8zqISstQRC+3rx588OHD7FdrVo16Bkb0tCzWq2OjIxkhcLo0aNLlsxaFcDe3l6lUu3du5dZPSRpSREdHY3PadOmYUMojp06dWIS4sGDB2PHjmWFQnBwcJMmTZiuHjlx4sSxY8dOnTo1adIkZt2QpCXC1atXO3fufO3aNWyjR+qjjz6ysxPleMa8QbyqdOl8rPz+igwePLhUqVKIdQt/zpw5s0WLFo0bN0bkjFkr1JYWN3/99Rfi2MOGDbt48WLx4sULs7jbLGjXjBs3rkKFCmhsM+uDrLQoiYqKwmdERMTOnTvRt4ztGjVq2IKelUql0LgoQhwcHFauXOnr69ulS5e7d+8yK4OstPhAUxk2GUEvtPFefciXuEBX3KJFi9avX8+sADTsYa4RrUBXObMayEqLg9jY2CVLlpw/fx7bMA5CENvW9My0y3oo/Pz8mHWANvbWrVvj4+Pfe+899BEy64CstLUTFhZWuXLl1atXu7m59erVywZlbP1cuHAB8chPP/20bdu2rKghSVsvCF/Do5s3b17Lli0ZoUN4Y0zfXWxVTJ06FU2huXPnsiKFHG+rY8uWLULnJ8wyOkJJz4b8999/CCUwq2TWrFnNmjV78803z507x4oOkrS1AOcN7bG0tDQEUUeOHIkURLD1rw0QAuhst562dHbeeuutgwcPrl27dunSpayIIMe7iFGpVCimaIbFxcUtX74cHSSMED+bN29G5AzCDggIYIULSbrIQBfIV199hXq9VatW6GsV0Uv2RUh6ejp8GW9vb2b13L9/f/z48Z07d+7fvz8rRMivK2xiYmKOHTvGdM3Ct99+G3rGNunZRE6cOLFgwQImBsqWLQtDDedrxIgRhdnFRZIuVNBOHjRokEY3RU67du1atGjBiPzg6OhoneHu3Pjwww+HDx+O33r//v2sUCDHuzBYtWoVoibbt29PTk52dXVlhO3x+eefQ2tz5sxhFoastAXZs2dPREQENtzd3X/44QdskJ5fkdTU1CdPnjARMnv27KZNmzZp0kQYAmg5yEqbHzSfvLy8pkyZolAoPvvsMycnJ0aYCdSSZ86cmTFjBhMnqJI++uijSpUq4ZNZBrLS5uTevXsDBw48fvw4071bi5JHejYvyM/8zjFuVTg7O69evRrhgO7du6O0MAtAVtoMIHYdGho6YMAAfKKTWVg+iiDyAHpGF1fXrl379evHzApZ6YKTlpaGChFNu2XLlgnrv4WEhJCeLUpSUpJI29IvERAQsG3bttjYWHRxCWuPmYtcrTTyTj83IpGdc+fOXb9+vU+fPsjAQhi2iW9xc3NjBSUjI0OlUjHxExYWhpJZr149Jn7ghKPkIFqGdjUiL23atGHmIFdJo/5gxIsgr2CZ7XQolUp7+0Jd2bB48YKvuobOs/R0KSxDh6dArz7EwMQPYqh6YwBJw4IiKs5eGXK8TSIzU7vCExwkqFpYTqWQ9UwIODo6SkPPL4H+6saNG6OX69W7uMhKG0GtVsfHx7u4uKAwsSKFrDTTrZjLdPOEMvFjaKUFUlJSEDOrUqXKq6y8RVY6Z9D4RJtN2Pb09CxyPRMCqJjQ9mESBZYDXVyQeo8ePe7fL+DKvkUv6Tt37rz99tuXL19mVgAcbMEOQNKCjOVyueVsAtwt65/qPTfgvOCH++uvv1ghggZn0ZroQiiu/fv3/+KLL8aNG7d582aWf4omd+7evaufVNHDwwNx4xIlSrDCBXI6cOCAYQq8U32c393d3ejU9r///vvixYsZUYg46WCFS+EXV3Rxbd++PTo6euTIkfn1SopG0jdu3NBvw81AfhX+24U3b95kuraZvp2JsgIf2/SuO+EKRGGi0cEKl6IqrujcGjZsmDBTiulnKUw/NCIi4ssvv4TL4efn98Ybb+DBhKgv0pcvX47yjVBw2bJl4TbUqFGD6cwg5NGiRQt4EahpKlWqhPvD54YNGwSPAg7M8OHDa9asOWrUKJi7atWq5XYKDv7f//7HdKMshZs5dOgQjkFNhvgnvOUffvjhzJkzMTExVatW7dSpk9F+S3w1PpcuXbpmzZoff/wRPvbJkyc3bdqEZ4F9Ll++/JgxY/J+ie/jjz++dOkSNg4fPozHDw4Ozi0f8sgiQ3D/W7duRelBtYKnGDJkiOFiqGYnLi4Oz3716lU0MWrXrg3LIywTI0yThB/6l19+OXHiBGJyCMPiZoSZSY8dO4afD75MgwYNunfvbuJ3nT59+ptvvkHANSgoqGPHjvoO2NzyPLdi8P3338MzWr9+PUylcIVff/0VP/2WLVtQDFDu9+7di/sPDAzEPXfp0kWonXv27ImnO378OIoujnd1dd2xYwfKz8OHD8uUKYNnR0nG0yE0tW3bNgSc7927h5zHAyIdBSOP4lqAR2D5pE6dOn///Te6uPA5a9YsU04x1UrDB0CdgaI2f/58tN2PHj26YsUKpD99+hTpeAz8ZlAIiiMOEEbDoPiGhYUdOXLkq6++QiY6ODgIbipy6p133sEp+/fv79atm+G35HZK3uBOfvvtNygZv+6bb76Jzj08fx7HI4j93XffMV0tiF8RP9u///6L/GrVqtXGjRsnT56MqgEKzPtLFy1ahF8Ip+ApoOc88iGPXXpu3bqFOiskJAQyGz16dHh4OIoCsxjIgU8//fS///57//33V65cWaxYMYRYHz16xHSTe+ETkm7WrNmuXbtwGLJIaDCjGblgwQI8MnIPnzjRlO+CnlERDxo0CDkMS4AcQOFBeh55nlsxgFAhj9DQUP3FUenUr18fesY1lyxZgh8Cssd3oTysWrVKf7V9+/ZBb3PnzoUjtnPnzp9//rlr164oLe3bt8fPB53jMKSjakA9NWPGjKFDh+KRUdezPItrAR6hYKCCaNSoEX4RfKPRg02VNPIIt4XHQ7FDRgwcOFD47ZEOW40CAdNdunRplF1k+u7du4WzsI0U7MIT4oYePHhgdOxbfk+BkYGdRE2Mu0JNCQuAs3KMK+DKUBfTdYG8NNMNamKUNvzMqP7RhYDKGDbT0N0yJX9yy4e8s0jgypUrqFl69+6NolO3bt158+bhiZjFwNfBsHzyySf4Llik9957D1knTPcvgJqxSZMm+ImrV6+O2xaaGLhn3B4snpubG7wME+esFvIW9gr28N1334U9EH7QvPM8x2IAI48U/fybcDQgG+gc29AbzObYsWNRY6KIwg9CfST83LCWuGGY1lq1auFq8K0qVKjQunVrVGR4BFQxyAQcBrnCNuCp8Wi4MVzW6ESfBXgEVlBwq3v27EE9hToi7yNNlTRqaFSB+nnh4d/Dx9CnC6MvmG6MG0qtvpEJx0Y/MEB4VRgN17y/KL+n4LuUSiWKiz7l9ddfx10lJiYKf6pUKhglphv7hYLLdL9x9qd77bXX9H9WrFgRn9evX2cmk0c+5J1FAnB/0J6HoUZTAg4hikh2z9yMQNKQK4q+8CcyBJkmtCMEhCHrAuhZEX4CmHHDyfGEXMobtHtfylv4n6h8mbE8z60YNG/eHC608INiA/UgzBe+BS0I+Kj6q+HRkKiPSxveKrR34cIFmHQ46igkpUqVggFnOvcEXvcHH3zQoUMH+NjwTRDSZ3lSsEcoMPgh4MShJkK1mJCQkNthpral0dLQN2AMQU2JTDFMQS7rY3QF6G/I7ynCrE4TJkx4KR01NAQMPeMAQcm5jTrCATD1hlNzCjHVfNWpeeRD3lkkAAnBhUMZhU+Lnw0Ntn79+lnuDRCULeSMEFDQg7Ki387xV4AADFfSM6WvXhi/mX3aU6N5nlsxaNiwIVww+N6oxOF1N27cGHUlvgWPs16H4cF6TRp2XsCooiSgDQxV41yYZbjZ8NqQ8zD1qHFwZTgjcODzDkoV+BFeEXjKuGe0mOAj5HiAqZJGDZFjEUfu4MEMU1BYC2EJRX3YU3Ch4da+JBuhmwG/GZyuvDNX+FUMB1cJT5qv6FQe+WBiFtXVgR8M7SX4wNOmTUOTT2/bzQseDYJ8aSIBo0vzoGY0fBBTOleQt8j87JPpFTjPkW+IfkGQcJ4RCxAiRngWyAltWijc8OAcZ/zG/bTVgTAYqgYEt3B706dPh1sLtetbE0YnADRLsSkYyAG0OHLba2qJgVOBZ0ZsWShkiHyiUxeBKKSjKStMRs1072+hkSbMemle0Bw1dITQMhE2oGQhc/WeKuwzfGzBJsOlNFpS8UQoH4Z5BC8On+XKlWMmk0c+mJJFKJ1QCySNGgrNPF9fX0TUEZK0UOWIRinKImo9fT0YGRmZoxdmCGwXYl2oTIUqEtvMGMh8PD78fH0KrB8aSiNGjChYnuNnRbsU4S50HKCK0bcd8ERwPfRlALkdFRWVY+8xYt34aqgiQAfOwtVwPDJEP+QWd3jq1Km878QsxcYSmOobwEnDY6NpDhvyzz//wEtB4cMP1q5dO9RnSEe4D9Ue4sAQ2EseXXZQUlZflsIAABAASURBVOGOwnHSK9MoaLQg8IDWC9NFGnGukI7fGD4qgpNoOOGXQKwbsUfEloW9uOccGzC4Sfx+aDtdvHgR9RSi5bggbCP0hhS4vigrhu3JHIEerl27hpoelUge+WBKFqE0IKqJPhhUW7gmoq/IXst1fsKxR8tz2bJluCW0yhBJQhsSZT3vs+Dv4fYQ6EaNiVzCWcwE0HJGPqN/DqcgwIaoMuSE9ILlOSoUhO5Q2cErxv3o6+vBgwfDdMPMCE1oxBcRq0d5yH4FWCPYdigW7QhEs1CY0bqGwUDTF9dEvAAZgpgZWj24McHw5lZcC/YIlsZUK42nQkagEOCxUSJhZJCJQjokhOYNPEZU8xAegvVG35WBOUKWoW8DakTMkJkA+jNh3BDSRGgE0UgEh/XdPOhjQCWNsgJ1oYFQuXJl/ah3FD4hlJIdXAF9D4hqok2Cx3ny5AmKHSKKsEUIjQpPlzfQKqJceHx4Kzglt3wwJYsQboVahHgmihcecOHChRbyugWQ+XC7UPRhZ9AjjbBT586d8z4FjUw0NXEWvFPkEgLmEydONDorDpwOlHj4t5AHnFJ0cQv90gXLc3j7iGnDPCLn0dunT0e4Gx1I6Etft24d7C3KAHzpHJcuQdnAN2Iv043ex7MIHeyfffbZ6tWrEbXGWfiEwUfZ6NWr17fffptbcS3YI1gaib+JhadDtS2NBVzpTSymkzQaU9J4iyb7m1img1rm7NmzOe6yoB2wBkxpSxMigqZnNIpkJY0GlbBqKQx19o5oxAKMRoNAHmMe0W2GHlFG6MbqGgbADEHI4L333mPmQ0rvS1sIKTveiHki9IUmnNAvbYiJE8fiCrntQi9uIbt/Vut4oz2Z28RmMKqmVJ2mI8SrpDdRUX6xUccbun3FtrSop4wuNApzHUma4tIo1JYmxAS1pY0i8TYJerD0g70JCVAk70uLi1yttOGIX/ESHh6+ZMkSo29KWj+v6HCi8SmNjh90AqOX2xq6f18dCwX5cpW0Rcc5FBqBgYGTJk2SxrO8CjIdTPy4urpmZGTQD5oHtCYWQYiPPCLeEm9LR0dHjx8/nhFSAZGRuLg4RuSOxCWNfunbt28zQiocPHhwzZo1jMgdibdJfHx8li5dygipgKitp6cnI3KH2tIEIT5sty2NpteoUaMYIRWSk5Olsb605ZC4pOGD5GuiT8LK+fPPP41OkWnjSLwt7ebmtnr1akZIBfygr/L6ii1AbWmCEB+225bOyMiQxuBBQiAlJeXx48eMyB2JS1omk127do0RUuH06dOLFi1iRO5IvC1tZ2f3ww8/MEIquLq6Fv66xeKC2tIEIT5sty3NdAuO5DbvLyE60tLSoqOjGZE70pd0eHh4ZmYmIyTBxYsXTVxm2WaR/nun69evN1zljBA1zs7OlluERBpIVtIhISHCS/8cx2k0GmFWkLfffnvu3LmMEC2v62BE7kjW8Q4KChKm8hBmFMSGr6/vkCFDGCFmMjIy8piJmWASlnTLli1fmpqndu3aRb4EGfGKXLt2bcqUKYzIHclKul+/fgEBAfo/YaL79u3LCJHj5OREk6vnjWQl7eHh0bFjR/3ahdWrV69UqRIjRE7FihXnzJnDiNyRcidWjx49ypQpw3Qmuk+fPowQP2hLR0ZGMiJ3ChjxvnEhXZmuzHmfMOE0n1M6b9rxwpGGx+u3Od0mn9vVXkzlWOuGw7iUQxUrVOSSAy6fTMz1+rldg3v5xrISTHw6w0RUnnlOKS+XyQOruji5MiIP7t69i37pTZs2MSIX8j0gdPP8iPgnSpmcU2U8L6FcTpLM2tb9wb+gyhwP5p+JOy9FC7fMeI4zVgkYfPXzK+d6fY7psyFPRWuvxmnvwDgcE3KXy/4VOV5cYS/D0Q6Oiq4jynqVppWfXmDYsGGpqanojMTnkydPSpQoge20tLRDhw4xm8Rsy9ytn37PwU3R9cPyrm6MsASndj/55cs7Az4LcPGipbyeg1DIxo0b9X8+ePAAnyVLlmRENvLRll439W6JMs4dhpUmPVuOBh28+00J2jj/bloCI/QMHDhQCIvogZVGryQjsmGqpE/8/kSj4Zv0oPfaCoPi/k7bVtxnxDOKFSvWrl07wxSY6HfffZcR2TBV0vfC0t09HRhRKLxWu1hKIr1q8gIQcNmyZfV/whWvUqUKI7JhqqTT05QKB4rZFBJuxezVSlpy9QVcXV27du0qLHDn7e1NA4dyw1RJK5W8SklvHRcSPI+mIk1N8TI9e/YsXbo0NmCfQ0JCGJETtKgnYX6UaezkntjHD5SpyaqMdI1GzTRqnpMxXu95oCdQ21Gv6+XTpXNyxutMhtyOU6u01Rkn53i1dkMm43iNtgdQpuCaB85Xl1HbKRSrPg3ns7oUdRfkWdZ1sj61p2gvorNZ+u/V9mtyz/+UK7Sz0ynsOGd3WZmKLg3bezHxQ5ImzMmBDTH3r6dkpKnldnKFnRyfdo52vHbwAy/0zOsHBXCcjGdapXKcTtj6fns5p9ApWZ+iPUA3vAApdk52wi6BrAOEa3JMw3iZdjDA83NlunOfDzp4NlpA+FOhkKvVvFqljovOfPwg7vyROEdn+Wu13d/s6s1Ei6mSRk0po47SwoLnDIqtSNi/Pjr8SrJMLnMr7lqhsSjNHbyDB5djLp2Ix7+azTxFarRNlTSadhpqShcW2uFpoprmcc3kO/Bzy1TxcfN1YqIFPn9ATe2UKTG3Ev49+jTsbNKQ6QFMbJgaHpNxTCb9ecqIfPPoVsbXH91y8XKu1KSsqPVsSMlgj6otAzmZYsXH4UxsmCpT1MEa6lUhXuRpjOq3lRFVmpUrXVWC61SVq+vrU7H4NxNuM1FhqqTlMu0/onDQyBjPrL0tHX419aeFEVVblZPbM6ni7e8SVMt/xUQxqdpUmao12n9E4SDTaLtamHWzb21khfr+TOo4eSmKB3iu/kw0HjhZXqIgfPv5HTcfFztXm+gFQdNaZif/aVEEEwOmSlpsXSoix7pz+48tj5XpmrKv29A7PBUa+T+JzIgMVzKrx1RJ08pZhQnPrLotffVUQskgT2ZjOHs67vr2AbN6TO7EkvEyeREUssFDey77cj6zMTjeetvSJ/fEyRSyEuU8mFUSeunwxKn1k1OeMnMTVMcPvgmC/My6MbkTS8Np1NZrqbt2b/0o8iGzADNmfrZ3306jh/22Y8u8BdOYDXD5ZIKTm42+ZmvnqDi0ydoX2ZNCeCwqKjI+3vy1ssD161fNeJgEyEhV+wRL4fWGAuBWwiU2MoNZNxZ8baNt+8YDBwzv3WuA8OfCRTNv376xetWmGzevjRjZb8b0hT9sWBMefsvbu3jzZm+NGT1eOOzu3fD5C6bdu38nJKTOgH7DDC+4/bdfTp36Oyzssr2DQ43Xaw0dOqZ0Kf8LoefGTxiJvX37dX7jjaazZ36RmZm57rsVp04fj4mJqlYtpGvnng0aNDZ6t6dO//PLLxuuXb/i5VW8WrUaw4e9r72xlnWwa9HiWStXLd2181hycvKvWzedOXvy7t3b3l7FGzVqOmTwKEdHx3Hjh1+8+C+OPHhwDx6wYoVKV678h6e7du2KRzHPhg3eRD64uLgwk+Fzm720qLl2LlUm45yLWaon+u79/w4eXRvx4Kqri2fl1xq/1XyYo6M23/459euhP78bNWTlhp8nRceE+/kEN2n0bt1aHYSzdu//+tzFvQ72zjVfb1OyeFlmMfzKe8Y9SGTWTX4i3mZqSivk2npk06Z1s2ctObDvxJjRE3b+/uuevTuQqFKpPp30fokSPuu/2zrivQ9+/mXDkyexwlmXLoV+vXxR1ao1Zs5c/NmnM54+jZsz93Ok1wypM2/OMmz8uGkn9IyNr75euHXb5q5dem3+cVfTJi2nzfjkz7+O5H1LqGUmTf6wZs26+N4P3v8EVc+ChdORvn/vP/j8eOJU6Jlp65SfN/+0vlfP/nPnLBsx4sNjfx6CbpG+bMmaypWrvfVW+6NHzkHPDx5GTPxkdHpG+vKvv581Y3F4+M2Pxg/P14K4HG+lQe87lxI5iw05in0SsXr9+ypVxtjhawf2WRAZfXPld6PUam2+yRV2aWlJO/Ys7tll8qKZp16v1mLLjtlP47WLY504s+3Ema3d2n/84YjvvT1LHTq6jlkMzl47Pez1c0nMijF9jDdn3jHeb77Zws+3lL29ffNmrevWbXjkyH4k/vX3HzEx0RC5j49vYGAQ1JWcnJV9VapU/37dlr59BkPDdes06PlOP5jrhMSXJ93LyMg4cHB3n3cHderY3cPdo13bzi1bvL1h47d538zlS6Ewtv36DsH31q/X6ItFK999d1D2w/Cla9f81KxpK9zDm42bw7k4c/ZE9sMOH95np7CDmMuWDcRTTJww9eat68f/OcbET3K8RqGwlKT/vbhfIbcb9O4CnxKBviWD3uk85WHk9cthfwp71WpV6+bDAspU5ziuTkh7nucfRt5A+vGTW16v2hIid3Z2h90ODqrDLIlMLou5b9W+t6mOt9rcb2JVCH5Nv126VJnDR/Zh4+HDCEjL19dPSIfrW7Jk1mLCcrn80aMH36z4Iuza5ZSUFCEx/mkcdGt42Rs3wpRKZd06DfUpITVq79v/O8T/0pGGVKsekp6ePmnKuDq16zds2MS/dBmINvthdnZ2Z8+dRLvg1u0bgtX19MyhVXnlysVKlap6eBQT/sTjlCrl/9+lC6gLmMhRqTItN0QBXncZ/youLln55uXp5+3lf+deaI1qLYWUsqWrChvOTu74TEtPgrBj4yL0HjjwL2XZZZJQoaSnFf20cK6uua7hUGRTIDg6OhlsO6akJGMjMTHBycnZ8DAHB0dh459//vz8fxNgpUcM/7B8+Qrnzp/+5NOx2S8rWPX3Pxz6UvrTuCd5SBre8vx5X/3115E13369YuXS2rXqDRo4Ai3qlw7D3r17d8DlRpUBe7523Tc5BsNxD9euXxXa4YY3wMSPdrYCZinS0pMjHl5FF5RhYmLSE4Nvf7k2Sc9I0WjUDg7Py4y9vWXfBkMOcFzRB5UR1sltl6mSfvWqWf2ildd71AAWUlC4u7tHWlqq4WGpqVkGeffe36pXDxk2dEz20w3xLq4d0jRh/JTSpV+Y9rlkSSPLHcLfxr/Bg0aeP3962/afJk8Zt33bCys5wCDs2r2tR/c+Hdp3zfsevLyL41ZxKcNED/dizGR0o+mtsTFtb69gnKXem3dz8y4XENKmxXDDRBeXvDrAHR1cZDK5SpWuT8lQpjJLwmuYk4tVD4M1VdIFqJzt7R0M9RkRcc9wb+jF840bNxO2b926HlROu/Kzr48f5I0weFBQsC79RmzsY+EYGHDs1Z/+999/5Pil/qXLCqtV6j1nBNKgRmdnZ5Y7oaHnM5QZkHTx4iXatOng61sKQeyo6MgSxZ+v54DQXVpaWvFnKXDvT5z8K8erlQ+qcPDQHsTk9QtcI4zv75+PSKypglKkAAAQAElEQVRMK2drDHl7lLB/HJXCLEMpnwrnL+4NCqypz7eomPAS3nnlG+y2ZzG/u/cvNX0jKyXs+j/Mkmg0zC/Qql8LNzk8JudkivzZDQS0EGoWPISNm9bFxsYY7kWj9PQZbWwJcSN0RLVq1Rbb6BZCwGzxktkQNsQ8c/Yk92fecnD5imfPncKRaMT+uvVHIRGqw2eZsoH4PHbs0NWwy5AufGbEwxAhh+pwAwg+Gx1/dvnKxekzPtm1ezv6t3ERRLahbdQgqB1KlCh5Tve9KGcId6FZ/vDRg4SE+IWLZ1avFpKUlCg07OEUIFz374WzqEF69Oir0WiWr/gCT4GKbPWar4YM6xV+5xYzHWsd1BNY1TlTaamWJPqlkG+/71uqVKbHPL63+8DyL5b3iYw2km81qrW6dPVo6KXD2P7j7w33HlxmFkOVooamg2o4MyvG5NFjal6Tmb+CNnbMRC9P746dm7Vu0yAjIx2RZ8O9fXoPWrfuGzQ4p03/pFu33u3bdWG6Rj/6h9SZmR06NR00pAe83ICAcsLxQ4aMhhX9fOr4t95uGB0dhX6sSq9V+WzSB4eP7Efv9NttOn6/ftW3336NI9ET/vHE/23+eT2++suvFpTy858w4fO8bxWh7Pbtui7/ZnHX7q3R4eTs7LJ0yRphyui+fYZAqFP/NyEtPW3qlLmODo6DBvfoN6AL2tvDho3Fn127t4qMetSxfTdYjI8/GXM7/Ka7m/u6tb84OTqNGNVvwKDu8EfQDYbmOhM/wTVcUK8nPU5nFgAh64ljN9vbOS1bNXDhVz3D7/77TpcpRsNdrZoOrl+78469X6ARDhPdqe04xhhvmSZ/zJ14Owdrf/nM1JUrV08O9/C2bz/MDO/Hwq8e+l7vL5d++/rrNRmRE7ERyj3r7o1dWoFZH+tn3FMzefl6fsz2uP5nhE9Zhy6ji/7Z81i50vTXNpgVxPmIoqdG42LpSRax0tZPeoaqywhrr8tMnyHUYF51EbL5p/U//bQ+x10BgUHLv/qOWRO8FU9UVLOlx5lDTx5diytVKeeR3vEJ0YuX98lxl5ODa1pGzr0vviWCxg43MiIoX3w+p2Vuu9TqTLk8h5IfWKb6sAHLcjvr1qmH7sXsmNVP+mCqpOUyZq55vBHNPnrkHCtcOnbs3rz5WznuUsitbn0CzronKqrdyuvMgSe5SdrN1Xv86I057kLcy97eMcddMpmZf4Xc7kF7G6oMe7scXiZT5DmLWkaycuScYGb1mD56jIl6Hm83Vzc3WhfbTNRpVezSPwl3zkWWq5ODFwoD6OVZihU15r2HG8cj/INd5I7M+qH2MVEQBk8LSE/MiI+07LgOK+HB5ccyGd95lDgigiRpq0QMM70NnVP+wZUYJnWirj1NepwybFY5JhJI0tYIrx0Tau2ytrdnYxeWv3zoTsKjNCZRHlyOS4xNHrWwPBMPJGlrhNP+MGKYwFHOxi4JfngtJvxsJJMcN/5+kBafPHxOIBMVJk+BoJ1qg2YJLSxEldOjFwUxdWbY0XtRNyw1XVQhc/9iLLwPV3fZe3NE42/rycebWDKay5vIhSEzAs8eeHr+6NO4h4mOrg4+wV4unuJbVifhUUrs3YS01Ax7R3mXEf7+r4khwJ0Nk4ea8OIeakJYmrptPPHv3OGES8fj7/37iOeZTMHJ5DIA/y7nwsPxHMv+BjbPvfhaNsdlrTJvuBZ8jhvaJeh1L1Xzz04UzjQ88fk1cYdyFGt5piqTV2vUmRrcrbuXfdMepYKt+8WMvLG6URaEqKnTygP/sHHtTPKdsOSkuMyMdLVa+YKkn4tQrhW0fkVUIZ2TaSdTNFwmVTcSWSt+JMpkWbty3mBaVeN4fJ32aroqQ7haVqKCZ2ptfSGcpbDjZApeYWfn6WNXuZ57mYpSWEyXJE1YhEr1XPGPEYWOqZJ2cOAUDtSWLiRgvmQK6owgCoKpknZ0sctMo4h3IRH7SCmn5byJAmFquQmu6ZH4tOgnRrQRbl1McPe2YwSRf0yVdJ2WbvaO3L51Fll3ijAkOY7FR6W/+7H0V2MnLEE+vLtB/wvQqPntX0XcumDVqw2IlyeRykMbonasDB8pqhGIhFXB5XeWpt+WR8Y8TNNk8pl5TkXGa3KdBSWP9Z7y2MVn9Tialm76AjQ5HSl0prBXQ+gLzeOLeF3HjP5PmfaNdJmbh6LfFAuu6kRIgzwmKsp3J1bXsbpXzNJYmjI/708biFU3vCCXw2ScdlALy0ncL40VeH6K7IVOzGxfN3zEiOnTppYq5f/84sYuy8u0kxDkdZjhIIZs3/jyKdyzKuLlA15MkcudqNOHeGUK2i/txJycrGfKlrzuJCE1xsnDzsnD6ieYIQhzIP2hJpmZmcL0vQRhC0i/rKtUKjs76hAibAWy0gQhKUjSBCEpSNIEISlsQtLUliZsB4lLWq1Wy+XUfUXYEBKXNHndhK1BkiYISUGSJghJIfHirlKpSNKETUFWmiAkBUmaICQFSZogJIX029I0zoSwKchKE4SkIEkThKQgSROEpCBJE4SkoPAYQUgKstIEISlI0gQhKSS+llqZMmUePXr066+/MoKQBA8fPly6dGnNmjVzOyDfq22Ijvv37//0009bt27t3r17jx49goODGUGIkL///hvGCeX5nXfe6d27d25ze0hf0nq26nB1dUWOtGnThhGEGEhNTf1VR4UKFVB0GzVqlPfxNiRpgdDQUOTOP//8g9yB0fbx8WEEYZVcuXJly5YtR48efUeHr6+vKWfZnKQFkpOTIext27aZWPMRRGGya9culE+ZTIbC2b59+3yda6OS1oP2Cbzx8PBwwWg7OzszgigihFAuaN26NQpklSpVWP6xdUkLREZGQtjIymbNmkHYr7/+OiOIQgQtQfjYd+7cgZJ79uzp4ODACgpJ+gX27t0Lbaenp0PY3bp1YwRhSVDSoGTYkqCgICj5jTfeYK8MSToHbty4AWHv3Lmzh45y5coxgjArV69ehZIPHToEJcMy+/n5MTNBks4VtVqN+Bny3cvLC8JG84YRxCuze/duFCroDkru2LEjMzckaeOcP38eRvvs2bPdu3fHz1C8eHFGEPkkKioKSoab3bJlS5SiqlWrMstAkjaVhIQEIYRWrVo1GO0GDRowgjCBEydOoNjcvHlT8LGdnJyYJSFJ55tjx45B2w8ePICw8Qu9SnCSkDAZGRlCj1RgYCCKyptvvskKBZJ0AYGkhRGmaGPjB7OcH0WIjrCwMBSM/fv3C6O+SpcuzQoRkvSrsmvXLkTREEvDj9epUydG2DDoBEVruWgLA0naPAgVM35R/JaIogUEBDDCZoiOjhZ87GbNmqEAINrCig6StDlRqVTC0HEfHx944y1atGCEpDl58iR+8Rs3bgiBFRcXF1bUkKQtwpkzZ2C0Q0NDhV/a09OTERJCqLvhY5cpUwa/b5MmTZjVQJK2IHFxcUK/V61ataDtunXrMkLkXL9+HUpGC0vokfL392dWBkm6MPjjjz8g7JiYGMFo03RoYmTfvn34EZVKJX7Bzp07M2uFJF143Lt3TzDa7du3R7GoVKkSI6weVMRC6Asdy/jVrP8tPZJ0EbBz504UEdhqGO0OHTowwio5ffo0fGz0ZQjdy66urkwMkKSLjCtXrkDYhw8fFrzxQh6QQORGZmYmlAx/ys/PDw3mpk2bMlFBki5i0tPThVFoiJ1C26IrQFICfVGoZHft2gUl47coW7YsEyEkaWsBPZwQ9tWrV4WXtD08PBhRWBw4cABiTk1NhbvUtWtXJmZI0tbF48ePBaNdv3797t27165dm5kbdTL76cv7yYkqdSbTaHiOsawSgP+0f/CM4/QHP/9L2GuIPuX5rpy2XuLF6xuiLYsv7pIrOIWdvGQphy5jzTZDgCGxsbFC93KjRo1gmWvUqMHED0naSjl48OC2bduePn0qGG2ZzDzroiiVbO2U275lnas08vYqbc+UaibjmIbX6Y/T6i3rT9020P+pJUv0uv91BwhnMSYczMsYp2HPFStcQX+uUNCECwpwz+qTrF2MaV64W7lcHn456dqpeKbg+08xpxt85swZiPnSpUtC97KbmxuTCiRpqyY8PFww2vAGYbQrVqzIXoGEaLZ5ye1+k8szsXFoY8zTmNShMwPZq6FWq4UeKR8fHyi5efPmTHKQpMXB9u3bIWwnJydY7LZt27ICsX7mveKlnZv2KMFEyC+L75av7t68pxcrELdu3YKSd+zYIfRISfi9GhrGJA666bh48SKEPX/+fKHfy8TlF/SkJWU2fFuUegYl/J3uhSUxlm9J79+/H5mWnJwMHxtdzUzqkKTFRA0dKSkpKKPDhg0rX748hN24cWNTzo2LUuPTXhzDJXLAyVkWrdKYfjxCX8glIfQ1duzYkJAQZhtIfDFaSeLi4jJw4MDdu3fD7KDUdujQYf369dB59iNbtWp1//79Z3+pMzNF3MhSqzWZ6SZJGqGvjz/+uH///gqFAp727NmzbUfPjKy0qHlDh/D+ffv27WGuYbT1PTGdO3eOj49///33YalsYYK0l0JfixYtYjYJWWnRgxIMx/LYsWOQ9Ndff927d2/0fjHdVBv4jIiIGDp0KJM0N2/enDdvHhzshw8fLlmyZMWKFZIMZZsIWWnp8LYOIbRbt25dWC2ZjrCwsA8++GD65C+YqMlpfMqBAweE0BfihbYQ+jIFkrTUCA4OnjRp0pEjR+B1Cykcx506dWr16pWurB0TLfpRLcwg9NWwYcMxY8bYVFPZKCRpaRIXF2c44Eyj0fx9/HjbaiKWtHb8BP981BfMMkJf7u7ujHgRkrQEQaCb6WSMkK+Tk5Pw6eFcTOTDijie8Yjt23LoyxRI0hLk8OHDixcv9vPzc3V1dXNzw6d25kqlyx8bMpmI4TnGIfTFiDwhSUuTiRMnvpQSF6Vk7D4jpA5JmhAJHCNMgSRtO4hfExzJ2jgkaUI80FuDJkCStiVErQiSs2nQgFDbgS981zs8/FbzlnUuXQplRGFBkibyomv31o8iHzJCPJDjTeRKVFRkfPxTRogKkjSRMw8eRvQfoJ3+tm+/zm+80XT2TO1bHxs2rj1wcHdsbEzJkr4hNWp/NG6SMOw0NTV1ybK5oaHnkpISAwOC2rbt3KXzOy9dMCk56fv1q06fOv40Pu61ilVatWrbvl0XZjoy6scyCZI0kTP+pcvMm7Ns0pRxP27aWcpPuxIIBLlr9/bx4ybXCKl9/vzpL5bM9vcv26tnf+z6bPIHmZmZs2Z+gSN37/nty68WvPZalcqVqhpecOHCGY8fR48bNymgbLkdO7csXTYP4q9a1eQlpjQUITMJaksTJgEb+9PPP/TvN6xx42Zurm7Nmrbq2qXXph/XqVSqU6f/QQDs4wlToWEPj2J9+wyuXj3khw1rXrrCxf/+bdKkZd06DUqW9Bn+3vvfLF/v7Z2fidDIRJsGWWnCJCIi7kG9lStX06dUMbILhgAAA7JJREFUrFg5OTn54cOIO3duOTo6liv3fC7hihUqH/lj/0tXgM63/LopISG+xuu16tZt+FrFyixfcDTSxCRI0rbDK3lkcXGx+HR0cNSnODk54zMtLfXJk1hHRyfDg52dnZH+0hU+/WT6779v/ePoAQjb1cW1a9deA/q/l4+ltjU00sQkSNK2Qz6m18yOi4t2btG09DR9SmqqdgJDL6/iLi4u6QbpICU1pXg2p9rdzb1f3yFwyy9fvvj38aMbN61zdXXr+U4/ZiIystImQW1p2+GVBFG+fEW5XH7lykV9SljYZTSqS5QoifB1enr6zVvXDXcFlnthTY+ExITtv/2CwziOgwc+etRHNUPq3Lh5jZkOWWnTIEnbDvkWRJmygfg8duzQ1bDLsLGtW7Xb9ON3J078lZiUePDgnt92/NKjR190YtWr16hUKf8lS+Zcu341Lu7Juu9WQNK93ulveCmFXIGA2fSZn8JE4xicfvPWterVaIIh80OON5ErpUv5v92mI/quqlWtsXTJ6jGjJ0DAs+ZMRn8VNNzn3cHv9h6Iw9AeRq/1qtXLRo8ZaG9vHxRUYdbMxTDFhpeCcz5z+qKvv1n0/ofa6UoRSxs5YlzbtzuZfjNMxpHjbQq0JpatEBel/HHB/UHTg5k4Ob4j5u7lpFGLxLdGXyFDVpoQCTxZH5MgSRMigaPRJiZBkiZEAk8DQk2CJG07kI2zCUjSBCEpSNK2g7jdVvRg8a82AM5GIEkT4oDXzrNEI6OMQ5ImCElBkrYdxD34isaOmQhJ2oYQ95y/NNDENEjStgNJwiYgSdsO5LjaBCRpm0Etk8lErGpOLpPbUcTbOCRpW8HLVy5mRTM+k3ewJ0kbh/LIZpAzhaPs3AGxTrUfHZHmXcqBEcYgSdsQIY28bl2MZyIk6qYyI1XTcYQvI4xBUyDYFjcvJP/x8+N67UoEh7gykXD8t8d3ryaOmlcejgZhFJK0zXFi19PLJ55qNBx+fLXS4NfneMZntba1A6oNywWn26vhDNL55yF0tNE1fFYSl9VZxslxdWFLw3itM8jJeF6jPYXn8DWccFX+2Xn6ROF03a1wCgemUTNHZ/ngqYGkZxMhSdsody6lPX6Ulqk0eBGCe951/UykWUm6kVvakvIs/YWDORnj9Zd5JnqE1zUaXaosa7phROfUwsnP5Mzpih/3rC7gn4s86/oOTooKNYq552dNDoIkTRCSgjqxCEJSkKQJQlKQpAlCUpCkCUJSkKQJQlKQpAlCUvwfAAD//yc/yQwAAAAGSURBVAMAxQmEXbIVPtMAAAAASUVORK5CYII=",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "901765b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph compiled! You can now interact with the Study Planner.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import TypedDict, Annotated, List, Dict\n",
    "import json\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage, BaseMessage, ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Topic(TypedDict):\n",
    "    name: str\n",
    "    completed: bool\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], lambda x, y: x + y]\n",
    "    study_plan: Dict[str, List[Topic]]\n",
    "\n",
    "\n",
    "\n",
    "@tool\n",
    "def add_subject(subject: str) -> str:\n",
    "    \"\"\"Adds a new subject to the study plan. Use this to create a subject before adding topics to it.\"\"\"\n",
    "\n",
    "    return f\"Successfully added subject '{subject}'. The user can now add topics to it.\"\n",
    "\n",
    "@tool\n",
    "def delete_subject(subject: str) -> str:\n",
    "    \"\"\"Deletes a subject and all its topics from the study plan.\"\"\"\n",
    "    return f\"Successfully deleted subject '{subject}'.\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def add_topics_to_subject(subject: str, topics: List[str]) -> str:\n",
    "    \"\"\"Adds a list of new topics to a specified subject. All topics are added as 'incomplete' by default.\"\"\"\n",
    "    return f\"Successfully added {len(topics)} topics to '{subject}'. The user should be notified.\"\n",
    "\n",
    "@tool\n",
    "def mark_topic_as_completed(subject: str, topic: str) -> str:\n",
    "    \"\"\"Marks a specific topic within a subject as completed.\"\"\"\n",
    "    return f\"Successfully marked '{topic}' in '{subject}' as completed. The user should be notified.\"\n",
    "\n",
    "@tool\n",
    "def list_topics(subject: str) -> str:\n",
    "    \"\"\"Lists all topics for a subject, noting which are complete and which are incomplete.\"\"\"\n",
    "    \n",
    "    return f\"Topic list for '{subject}' has been retrieved and will be provided to the user.\"\n",
    "\n",
    "\n",
    "\n",
    "tools = [add_subject, delete_subject, add_topics_to_subject, mark_topic_as_completed, list_topics]\n",
    "\n",
    "\n",
    "def update_state_from_tool_calls(state: GraphState) -> GraphState:\n",
    "    print(\"---UPDATING STUDY PLAN---\")\n",
    "    last_message = state['messages'][-1]\n",
    "    if not hasattr(last_message, 'tool_calls') or not last_message.tool_calls:\n",
    "        return state\n",
    "\n",
    "    # Make a copy to avoid modifying the state in place\n",
    "    new_plan = state.get('study_plan', {}).copy()\n",
    "\n",
    "    for tool_call in last_message.tool_calls:\n",
    "        tool_name = tool_call.get('name')\n",
    "        tool_args = tool_call.get('args', {})\n",
    "        subject = tool_args.get('subject')\n",
    "\n",
    "        # Logic for each tool\n",
    "        if tool_name == 'add_subject':\n",
    "            if subject and subject not in new_plan:\n",
    "                new_plan[subject] = []\n",
    "                print(f\"Added subject: {subject}\")\n",
    "\n",
    "        elif tool_name == 'delete_subject':\n",
    "            if subject and subject in new_plan:\n",
    "                del new_plan[subject]\n",
    "                print(f\"Deleted subject: {subject}\")\n",
    "\n",
    "        elif tool_name == 'add_topics_to_subject':\n",
    "            topics_to_add = tool_args.get('topics', [])\n",
    "            if subject and subject in new_plan and topics_to_add:\n",
    "                existing_topic_names = {t['name'] for t in new_plan[subject]}\n",
    "                for topic_name in topics_to_add:\n",
    "                    if topic_name not in existing_topic_names:\n",
    "                        new_plan[subject].append({\"name\": topic_name, \"completed\": False})\n",
    "                print(f\"Added topics to {subject}: {topics_to_add}\")\n",
    "\n",
    "        elif tool_name == 'mark_topic_as_completed':\n",
    "            topic_to_mark = tool_args.get('topic')\n",
    "            if subject and topic_to_mark and subject in new_plan:\n",
    "                for topic_obj in new_plan.get(subject, []):\n",
    "                    if topic_obj['name'] == topic_to_mark:\n",
    "                        topic_obj['completed'] = True\n",
    "                        print(f\"Marked '{topic_to_mark}' in '{subject}' as complete.\")\n",
    "                        break\n",
    "                        \n",
    "        elif tool_name == 'list_topics':\n",
    "          \n",
    "            if subject in new_plan:\n",
    "                \n",
    "                tool_call_id = tool_call.get('id')\n",
    "                subject_data = new_plan[subject]\n",
    "                observation = json.dumps(subject_data)\n",
    "               \n",
    "                tool_message = ToolMessage(content=observation, tool_call_id=tool_call_id)\n",
    "                \n",
    "                \n",
    "                for i, msg in enumerate(state['messages']):\n",
    "                    if isinstance(msg, ToolMessage) and msg.tool_call_id == tool_call_id:\n",
    "                        state['messages'][i] = tool_message\n",
    "                        break\n",
    "\n",
    "\n",
    "    return {\"study_plan\": new_plan}\n",
    "\n",
    "\n",
    "\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro-latest\", temperature=0)\n",
    "model_with_tools = model.bind_tools(tools)\n",
    "\n",
    "def call_model(state: GraphState):\n",
    "    print(\"---AGENT---\")\n",
    "\n",
    "    current_plan_str = json.dumps(state['study_plan'])\n",
    "    state['messages'].append(\n",
    "        HumanMessage(content=f\"Here is the current study plan for your reference: {current_plan_str}\")\n",
    "    )\n",
    "    response = model_with_tools.invoke(state['messages'])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "\n",
    "def should_continue(state: GraphState):\n",
    "    last_message = state['messages'][-1]\n",
    "    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "        return \"continue_to_tools\"\n",
    "    else:\n",
    "        return \"end_conversation\"\n",
    "\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"update_state\", update_state_from_tool_calls)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\"continue_to_tools\": \"update_state\", \"end_conversation\": END},\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"update_state\", \"tools\")\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "\n",
    "sam = workflow.compile()\n",
    "print(\"Graph compiled! You can now interact with the Study Planner.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f664817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---AGENT---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
      "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "}\n",
      "violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "}\n",
      "violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 52\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
      "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "}\n",
      "violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "}\n",
      "violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 50\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "}\n",
      "violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "}\n",
      "violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
      "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 45\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
      "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "}\n",
      "violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "}\n",
      "violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 36\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m state = {\n\u001b[32m      2\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [HumanMessage(content=\u001b[33m\"\u001b[39m\u001b[33mHey, I want to start studying Physics. Can you add topics: Kinematics, Optics, and Thermodynamics?\u001b[39m\u001b[33m\"\u001b[39m)],\n\u001b[32m      3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mstudy_plan\u001b[39m\u001b[33m\"\u001b[39m: {} \u001b[38;5;66;03m# Start with an empty plan\u001b[39;00m\n\u001b[32m      4\u001b[39m }\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m final_state = \u001b[43msam\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m---FINAL RESPONSE 1---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(final_state[\u001b[33m'\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m'\u001b[39m][-\u001b[32m1\u001b[39m].content)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Ai agents\\iambesideyou\\beside\\Lib\\site-packages\\langgraph\\pregel\\main.py:3026\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3023\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3024\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3026\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3027\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3028\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3029\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3030\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3031\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3032\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3033\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3034\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3035\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3036\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3037\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3038\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3039\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3040\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3041\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Ai agents\\iambesideyou\\beside\\Lib\\site-packages\\langgraph\\pregel\\main.py:2647\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2645\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2646\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2647\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2650\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2653\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2654\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2657\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Ai agents\\iambesideyou\\beside\\Lib\\site-packages\\langgraph\\pregel\\_runner.py:162\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    160\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Ai agents\\iambesideyou\\beside\\Lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Ai agents\\iambesideyou\\beside\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:657\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    655\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    656\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m657\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Ai agents\\iambesideyou\\beside\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:401\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    399\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    403\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 133\u001b[39m, in \u001b[36mcall_model\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m    129\u001b[39m current_plan_str = json.dumps(state[\u001b[33m'\u001b[39m\u001b[33mstudy_plan\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m    130\u001b[39m state[\u001b[33m'\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m'\u001b[39m].append(\n\u001b[32m    131\u001b[39m     HumanMessage(content=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mHere is the current study plan for your reference: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_plan_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    132\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m response = \u001b[43mmodel_with_tools\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [response]}\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Ai agents\\iambesideyou\\beside\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5710\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5703\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5704\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5705\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5708\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5709\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5710\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5711\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5712\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5713\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5714\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Ai agents\\iambesideyou\\beside\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:1490\u001b[39m, in \u001b[36mChatGoogleGenerativeAI.invoke\u001b[39m\u001b[34m(self, input, config, code_execution, stop, **kwargs)\u001b[39m\n\u001b[32m   1485\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1486\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1487\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mTools are already defined.code_execution tool can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt be defined\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1488\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1490\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Ai agents\\iambesideyou\\beside\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:395\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    385\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    390\u001b[39m     **kwargs: Any,\n\u001b[32m    391\u001b[39m ) -> BaseMessage:\n\u001b[32m    392\u001b[39m     config = ensure_config(config)\n\u001b[32m    393\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    394\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    405\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Ai agents\\iambesideyou\\beside\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1023\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1014\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1020\u001b[39m     **kwargs: Any,\n\u001b[32m   1021\u001b[39m ) -> LLMResult:\n\u001b[32m   1022\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1023\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Ai agents\\iambesideyou\\beside\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:840\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    837\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    838\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    839\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m840\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    841\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    846\u001b[39m         )\n\u001b[32m    847\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    848\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Ai agents\\iambesideyou\\beside\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1089\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1087\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1088\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1089\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1090\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1091\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1093\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Ai agents\\iambesideyou\\beside\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:1597\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   1570\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate\u001b[39m(\n\u001b[32m   1571\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1572\u001b[39m     messages: List[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1583\u001b[39m     **kwargs: Any,\n\u001b[32m   1584\u001b[39m ) -> ChatResult:\n\u001b[32m   1585\u001b[39m     request = \u001b[38;5;28mself\u001b[39m._prepare_request(\n\u001b[32m   1586\u001b[39m         messages,\n\u001b[32m   1587\u001b[39m         stop=stop,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1595\u001b[39m         **kwargs,\n\u001b[32m   1596\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1597\u001b[39m     response: GenerateContentResponse = \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1598\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1599\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1600\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_method\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1601\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdefault_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1602\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1603\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Ai agents\\iambesideyou\\beside\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:247\u001b[39m, in \u001b[36m_chat_with_retry\u001b[39m\u001b[34m(generation_method, **kwargs)\u001b[39m\n\u001b[32m    238\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    240\u001b[39m params = (\n\u001b[32m    241\u001b[39m     {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m _allowed_params_prediction_service}\n\u001b[32m    242\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (request := kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m   (...)\u001b[39m\u001b[32m    245\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m kwargs\n\u001b[32m    246\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Ai agents\\iambesideyou\\beside\\Lib\\site-packages\\tenacity\\__init__.py:338\u001b[39m, in \u001b[36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    336\u001b[39m copy = \u001b[38;5;28mself\u001b[39m.copy()\n\u001b[32m    337\u001b[39m wrapped_f.statistics = copy.statistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Ai agents\\iambesideyou\\beside\\Lib\\site-packages\\tenacity\\__init__.py:487\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    485\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoSleep):\n\u001b[32m    486\u001b[39m     retry_state.prepare_for_next_attempt()\n\u001b[32m--> \u001b[39m\u001b[32m487\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    489\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m do\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Ai agents\\iambesideyou\\beside\\Lib\\site-packages\\tenacity\\nap.py:31\u001b[39m, in \u001b[36msleep\u001b[39m\u001b[34m(seconds)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msleep\u001b[39m(seconds: \u001b[38;5;28mfloat\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     26\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[33;03m    Sleep strategy that delays execution for a given number of seconds.\u001b[39;00m\n\u001b[32m     28\u001b[39m \n\u001b[32m     29\u001b[39m \u001b[33;03m    This is the default strategy, and may be mocked out for unit testing.\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseconds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "state = {\n",
    "    \"messages\": [HumanMessage(content=\"Hey, I want to start studying Physics. Can you add topics: Kinematics, Optics, and Thermodynamics?\")],\n",
    "    \"study_plan\": {} # Start with an empty plan\n",
    "}\n",
    "\n",
    "\n",
    "final_state = sam.invoke(state)\n",
    "\n",
    "print(\"\\n---FINAL RESPONSE 1---\")\n",
    "print(final_state['messages'][-1].content)\n",
    "print(\"\\n---UPDATED STUDY PLAN 1---\")\n",
    "print(json.dumps(final_state['study_plan'], indent=2))\n",
    "\n",
    "\n",
    "state_2 = final_state\n",
    "state_2['messages'].append(HumanMessage(content=\"Great. I've just finished studying Optics.\"))\n",
    "\n",
    "final_state_2 = sam.invoke(state_2)\n",
    "\n",
    "print(\"\\n---FINAL RESPONSE 2---\")\n",
    "print(final_state_2['messages'][-1].content)\n",
    "print(\"\\n---UPDATED STUDY PLAN 2---\")\n",
    "print(json.dumps(final_state_2['study_plan'], indent=2))\n",
    "\n",
    "\n",
    "state_3 = final_state_2\n",
    "state_3['messages'].append(HumanMessage(content=\"What should I study next in Physics?\"))\n",
    "\n",
    "final_state_3 = app.invoke(state_3)\n",
    "\n",
    "print(\"\\n---FINAL RESPONSE 3---\")\n",
    "print(final_state_3['messages'][-1].content)\n",
    "print(\"\\n---FINAL STUDY PLAN 3---\")\n",
    "print(json.dumps(final_state_3['study_plan'], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e70742",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "state = {\n",
    "    \"messages\": [HumanMessage(content=\"Hey, I want to start studying Physics. Can you add topics: Kinematics, Optics, and Thermodynamics?\")],\n",
    "    \"study_plan\": {} # Start with an empty plan\n",
    "}\n",
    "\n",
    "\n",
    "final_state = sam.invoke(state)\n",
    "\n",
    "print(\"\\n---FINAL RESPONSE 1---\")\n",
    "print(final_state['messages'][-1].content)\n",
    "print(\"\\n---UPDATED STUDY PLAN 1---\")\n",
    "print(json.dumps(final_state['study_plan'], indent=2))\n",
    "\n",
    "\n",
    "state_2 = final_state\n",
    "state_2['messages'].append(HumanMessage(content=\"Great. I've just finished studying Optics.\"))\n",
    "\n",
    "final_state_2 = sam.invoke(state_2)\n",
    "\n",
    "print(\"\\n---FINAL RESPONSE 2---\")\n",
    "print(final_state_2['messages'][-1].content)\n",
    "print(\"\\n---UPDATED STUDY PLAN 2---\")\n",
    "print(json.dumps(final_state_2['study_plan'], indent=2))\n",
    "\n",
    "\n",
    "state_3 = final_state_2\n",
    "state_3['messages'].append(HumanMessage(content=\"What should I study next in Physics?\"))\n",
    "\n",
    "final_state_3 = app.invoke(state_3)\n",
    "\n",
    "print(\"\\n---FINAL RESPONSE 3---\")\n",
    "print(final_state_3['messages'][-1].content)\n",
    "print(\"\\n---FINAL STUDY PLAN 3---\")\n",
    "print(json.dumps(final_state_3['study_plan'], indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beside",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
